"""
gdacs_api_to_csv_xy.py
Fetch GDACS events (official GeoJSON API) and write:
  1) gdacs_events_flat.csv       — one row per event (with centroid x,y + xy_rings_json + vertices_json)
  2) gdacs_events_vertices.csv   — one row per vertex (x,y) for drawing exact shapes

Requires: requests, pandas
"""

import json
from datetime import datetime, timedelta, timezone
from typing import Any, Dict, List, Optional, Tuple, Iterable

import requests
import pandas as pd

API_BASE = "https://www.gdacs.org/gdacsapi/api/events/geteventlist/SEARCH"

def _safe_json(resp: requests.Response) -> Optional[Dict[str, Any]]:
    ctype = (resp.headers.get("Content-Type") or "").lower()
    text = resp.text
    if "application/json" not in ctype and not (text.strip().startswith("{") or text.strip().startswith("[")):
        return None
    try:
        return resp.json()
    except Exception:
        return None

def _centroid_xy(points_xy: List[Tuple[float, float]]) -> Tuple[Optional[float], Optional[float]]:
    if not points_xy:
        return None, None
    x = sum(p[0] for p in points_xy) / len(points_xy)
    y = sum(p[1] for p in points_xy) / len(points_xy)
    return x, y

def _geometry_to_xy_rings(geom_obj: Dict[str, Any]) -> List[List[Tuple[float, float]]]:
    if not geom_obj or not isinstance(geom_obj, dict):
        return []

    gtype = str(geom_obj.get("type") or "").lower()
    coords = geom_obj.get("coordinates")

    if gtype == "point" and isinstance(coords, (list, tuple)) and len(coords) >= 2:
        try:
            x, y = float(coords[0]), float(coords[1])
            return [[(x, y)]]  # single ring with one vertex
        except Exception:
            return []

    if gtype == "polygon" and isinstance(coords, list):
        rings: List[List[Tuple[float, float]]] = []
        for ring in coords:
            if isinstance(ring, list):
                ring_pts: List[Tuple[float, float]] = []
                for xy in ring:
                    if isinstance(xy, (list, tuple)) and len(xy) >= 2:
                        try:
                            x, y = float(xy[0]), float(xy[1])
                            ring_pts.append((x, y))
                        except Exception:
                            pass
                if ring_pts:
                    rings.append(ring_pts)
        return rings

    if gtype == "multipolygon" and isinstance(coords, list):
        rings: List[List[Tuple[float, float]]] = []
        for poly in coords:
            if isinstance(poly, list):
                for ring in poly:
                    if isinstance(ring, list):
                        ring_pts: List[Tuple[float, float]] = []
                        for xy in ring:
                            if isinstance(xy, (list, tuple)) and len(xy) >= 2:
                                try:
                                    x, y = float(xy[0]), float(xy[1])
                                    ring_pts.append((x, y))
                                except Exception:
                                    pass
                        if ring_pts:
                            rings.append(ring_pts)
        return rings

    return []

def _flatten_feature_neutral(ft: Dict[str, Any], sep: str = "__") -> Dict[str, Any]:
    out: Dict[str, Any] = {}

    # top-level (except geometry/properties)
    for k, v in ft.items():
        if k not in ("properties", "geometry"):
            out[f"feature{sep}{k}"] = v

    # properties (preserve; dump complex)
    props = ft.get("properties", {}) or {}
    for k, v in props.items():
        if isinstance(v, (dict, list)):
            out[k] = json.dumps(v, ensure_ascii=False)
        else:
            out[k] = v

    # geometry neutralization
    geom = ft.get("geometry") or {}
    out["geometry_raw"] = json.dumps(geom, ensure_ascii=False) if geom else ""
    rings = _geometry_to_xy_rings(geom)

    # --- NEW: vertices_json + counts (flatten all rings into one list of [x,y]) ---
    flattened_vertices = [[x, y] for ring in rings for (x, y) in ring]
    out["vertices_json"] = json.dumps(flattened_vertices, ensure_ascii=False) if flattened_vertices else ""
    out["rings_count"] = len(rings)
    out["vertices_count"] = len(flattened_vertices)
    # ------------------------------------------------------------------------------

    # keep structured rings too
    rings_xy_lists = [[[x, y] for (x, y) in ring] for ring in rings]
    out["xy_rings_json"] = json.dumps(rings_xy_lists, ensure_ascii=False) if rings_xy_lists else ""

    # centroid as plain x,y
    all_pts = [(x, y) for ring in rings for (x, y) in ring]
    if rings and len(rings[0]) == 1:
        x, y = rings[0][0]   # point-as-ring
    else:
        x, y = _centroid_xy(all_pts)

    out["x"] = x  # longitude
    out["y"] = y  # latitude
    return out

def _explode_vertices_rows(ft: Dict[str, Any], keep_keys: Iterable[str]) -> List[Dict[str, Any]]:
    rows: List[Dict[str, Any]] = []
    fid = ft.get("id")
    props = ft.get("properties", {}) or {}
    geom = ft.get("geometry") or {}
    rings = _geometry_to_xy_rings(geom)
    if not rings:
        return rows

    base = {"feature__id": fid}
    for k in keep_keys:
        base[k] = props.get(k)

    for r_idx, ring in enumerate(rings):
        for v_idx, (x, y) in enumerate(ring):
            row = dict(base)
            row["ring_index"] = r_idx
            row["vertex_index"] = v_idx
            row["x"] = x
            row["y"] = y
            rows.append(row)
    return rows

def fetch_gdacs(fromdate: str, todate: str,
                eventlist: str = "EQ;TC;FL;VO;DR;WF",
                alertlevel: str = "red;orange;green",
                pagesize: int = 100,
                max_pages: int = 300,
                max_retries_per_page: int = 4,
                backoff_sec: float = 1.5) -> List[Dict[str, Any]]:

    params = {
        "eventlist": eventlist,
        "fromdate": fromdate,
        "todate": todate,
        "alertlevel": alertlevel,
        "pagesize": pagesize,
    }

    all_features: List[Dict[str, Any]] = []
    for page in range(1, max_pages + 1):
        last_error = None
        for attempt in range(1, max_retries_per_page + 1):
            try:
                q = params.copy()
                q["pagenumber"] = page
                resp = requests.get(API_BASE, params=q, timeout=60)
                if resp.status_code in (429,) or resp.status_code >= 500:
                    last_error = f"HTTP {resp.status_code}"
                    import time; time.sleep(backoff_sec * (attempt + 1))
                    continue
                if resp.status_code != 200:
                    last_error = f"HTTP {resp.status_code}"
                    import time; time.sleep(backoff_sec * attempt)
                    continue

                data = _safe_json(resp)
                if data is None:
                    last_error = "Non-JSON response"
                    import time; time.sleep(backoff_sec * attempt)
                    continue

                feats = data.get("features", [])
                if not feats:
                    return all_features

                all_features.extend(feats)

                if len(feats) < pagesize:
                    return all_features

                break
            except requests.RequestException as e:
                last_error = f"{type(e).__name__}: {e}"
                import time; time.sleep(backoff_sec * attempt)
        else:
            print(f"[WARN] Page {page} failed. Last error: {last_error}")
            break

    return all_features

if __name__ == "__main__":
    today = datetime.now(timezone.utc).date()
    FROM = (today - timedelta(days=14)).isoformat()
    TO   = today.isoformat()

    print(f"[GDACS] Fetching {FROM} → {TO}")
    features = fetch_gdacs(FROM, TO)
    print(f"[GDACS] Total features: {len(features)}")

    # 1) Event-level CSV with ALL vertices packed into vertices_json
    flat_rows = [_flatten_feature_neutral(ft) for ft in features]
    df_flat = pd.DataFrame(flat_rows)
    if "datetime" in df_flat.columns:
        df_flat["__dt"] = pd.to_datetime(df_flat["datetime"], errors="coerce", utc=True)
        df_flat = df_flat.sort_values("__dt", ascending=False).drop(columns=["__dt"])
    df_flat.to_csv("gdacs_events_flat.csv", index=False)
    print(f"[GDACS] Wrote: gdacs_events_flat.csv  (rows={df_flat.shape[0]}, cols={df_flat.shape[1]})")

    # 2) Vertex-level CSV (one row per vertex)
    keep_props = ("eventtype", "alertlevel", "country", "eventname", "glide")
    vertex_rows: List[Dict[str, Any]] = []
    for ft in features:
        vertex_rows.extend(_explode_vertices_rows(ft, keep_keys=keep_props))
    df_vertices = pd.DataFrame(vertex_rows)
    if not df_vertices.empty:
        df_vertices.to_csv("gdacs_events_vertices.csv", index=False)
        print(f"[GDACS] Wrote: gdacs_events_vertices.csv (rows={df_vertices.shape[0]}, cols={df_vertices.shape[1]})")
    else:
        print("[GDACS] No polygon/point vertices found in this time range.")

    # Raw JSON for reproducibility
    with open("gdacs_events_raw.json", "w", encoding="utf-8") as f:
        json.dump({"type": "FeatureCollection","features":features}, f, ensure_ascii=False, indent=2)
    print("[GDACS] Wrote: gdacs_events_raw.json")
